{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lgb_params = {\n",
    "                    'boosting_type': 'gbdt',\n",
    "                    'objective': 'tweedie',\n",
    "                    'tweedie_variance_power': 1.1,\n",
    "                    'metric': 'rmse',\n",
    "                    'subsample': 0.5,\n",
    "                    'subsample_freq': 1,\n",
    "                    'learning_rate': 0.015,\n",
    "                    'num_leaves': 2**11-1,\n",
    "                    'min_data_in_leaf': 2**12-1,\n",
    "                    'feature_fraction': 0.5,\n",
    "                    'max_bin': 100,\n",
    "                    'n_estimators': 3000,\n",
    "                    'boost_from_average': False,\n",
    "                    'verbose': -1,\n",
    "                } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params=lgb_params = {\n",
    "    #— core boosting and loss\n",
    "    'boosting_type':       'gbdt',\n",
    "    'objective':           'tweedie',            # good for non‐negative, skewed sales\n",
    "    'tweedie_variance_power': 1.1,                # often ~1.1 in M5‐style contests\n",
    "    'metric':              'rmse',               # track RMSE on hold‐out\n",
    "\n",
    "    #— capacity / interaction constraints\n",
    "    'num_leaves':          2**8 - 1,             # ~255 leaves; controls tree complexity\n",
    "    'max_depth':           10,                   # cap depth to avoid overfitting\n",
    "    'min_data_in_leaf':    100,                  # require 100 samples per leaf\n",
    "\n",
    "    #— regularization\n",
    "    'feature_fraction':    0.8,                  # randomly select 80% of features each tree\n",
    "    'bagging_fraction':    0.8,                  # bag 80% of data per iteration\n",
    "    'bagging_freq':        5,                    # perform bagging every 5 rounds\n",
    "    'lambda_l1':           0.1,                  # L1 regularization\n",
    "    'lambda_l2':           0.1,                  # L2 regularization\n",
    "\n",
    "    #— learning rate & early stopping\n",
    "    'learning_rate':       0.03,                 # slow and steady\n",
    "    'n_estimators':        3000,                 # large cap; will stop early\n",
    "    'early_stopping_rounds': 100,                # if no gain in 100 rounds → stop\n",
    "\n",
    "    #— data bucketing & performance\n",
    "    'max_bin':             255,                  # finer splits for numeric\n",
    "    'subsample':           0.8,                  # equivalent to bagging_fraction\n",
    "    'subsample_freq':      1,                    # subsample every iteration\n",
    "\n",
    "    #— reproducibility & verbosity\n",
    "    'seed':                42,\n",
    "    'verbose':             -1,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df = pd.read_csv('./data/M4-daily-train.csv') # 91 M\n",
    "#df=df.drop(['V1'],axis=1)\n",
    "#df = pd.read_csv('./data/M5-sales_train_evaluation.csv') # 91 M\n",
    "raw_data_dir= './data/M5-'\n",
    "train_df = pd.read_csv(raw_data_dir+'sales_train_evaluation.csv')\n",
    "prices_df = pd.read_csv(raw_data_dir+'sell_prices.csv')\n",
    "calendar_df = pd.read_csv(raw_data_dir+'calendar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'sales'         # Our main target\n",
    "END_TRAIN = 1941         # Last day in train set\n",
    "MAIN_INDEX = ['d']\n",
    "index_columns = ['item_id','dept_id','cat_id','store_id','state_id']\n",
    "\n",
    "grid_df = pd.melt(train_df, \n",
    "                  id_vars = index_columns, \n",
    "                  var_name = 'd', \n",
    "                  value_name = TARGET)\n",
    "\n",
    "calendar_df=calendar_df.reset_index().rename(columns={'index':'d'})\n",
    "calendar_df['d']='d_'+calendar_df['d'].astype(str)\n",
    "\n",
    "\n",
    "# adding calendar features\n",
    "grid_df=grid_df.merge(calendar_df, on='d', how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prices_df.loc[lambda x:x['item_id']=='HOBBIES_1_001']\\\n",
    "    .loc[lambda x:x['store_id']=='CA_2']\\\n",
    "    .set_index('wm_yr_wk').sort_index()['sell_price'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>11101</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>11101</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>11101</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>11101</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>d_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>11101</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59181085</th>\n",
       "      <td>FOODS_3_823</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>d_1941</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-05-23</td>\n",
       "      <td>11617</td>\n",
       "      <td>Monday</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59181086</th>\n",
       "      <td>FOODS_3_824</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>d_1941</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-23</td>\n",
       "      <td>11617</td>\n",
       "      <td>Monday</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59181087</th>\n",
       "      <td>FOODS_3_825</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>d_1941</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-05-23</td>\n",
       "      <td>11617</td>\n",
       "      <td>Monday</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59181088</th>\n",
       "      <td>FOODS_3_826</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>d_1941</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-23</td>\n",
       "      <td>11617</td>\n",
       "      <td>Monday</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59181089</th>\n",
       "      <td>FOODS_3_827</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>d_1941</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-05-23</td>\n",
       "      <td>11617</td>\n",
       "      <td>Monday</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59181090 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                item_id    dept_id   cat_id store_id state_id       d  sales  \\\n",
       "0         HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1       CA     d_1      0   \n",
       "1         HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1       CA     d_1      0   \n",
       "2         HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1       CA     d_1      0   \n",
       "3         HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1       CA     d_1      0   \n",
       "4         HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1       CA     d_1      0   \n",
       "...                 ...        ...      ...      ...      ...     ...    ...   \n",
       "59181085    FOODS_3_823    FOODS_3    FOODS     WI_3       WI  d_1941      1   \n",
       "59181086    FOODS_3_824    FOODS_3    FOODS     WI_3       WI  d_1941      0   \n",
       "59181087    FOODS_3_825    FOODS_3    FOODS     WI_3       WI  d_1941      2   \n",
       "59181088    FOODS_3_826    FOODS_3    FOODS     WI_3       WI  d_1941      0   \n",
       "59181089    FOODS_3_827    FOODS_3    FOODS     WI_3       WI  d_1941      1   \n",
       "\n",
       "                date  wm_yr_wk weekday  wday  month  year event_name_1  \\\n",
       "0         2011-01-30     11101  Sunday     2      1  2011          NaN   \n",
       "1         2011-01-30     11101  Sunday     2      1  2011          NaN   \n",
       "2         2011-01-30     11101  Sunday     2      1  2011          NaN   \n",
       "3         2011-01-30     11101  Sunday     2      1  2011          NaN   \n",
       "4         2011-01-30     11101  Sunday     2      1  2011          NaN   \n",
       "...              ...       ...     ...   ...    ...   ...          ...   \n",
       "59181085  2016-05-23     11617  Monday     3      5  2016          NaN   \n",
       "59181086  2016-05-23     11617  Monday     3      5  2016          NaN   \n",
       "59181087  2016-05-23     11617  Monday     3      5  2016          NaN   \n",
       "59181088  2016-05-23     11617  Monday     3      5  2016          NaN   \n",
       "59181089  2016-05-23     11617  Monday     3      5  2016          NaN   \n",
       "\n",
       "         event_type_1 event_name_2 event_type_2  snap_CA  snap_TX  snap_WI  \n",
       "0                 NaN          NaN          NaN        0        0        0  \n",
       "1                 NaN          NaN          NaN        0        0        0  \n",
       "2                 NaN          NaN          NaN        0        0        0  \n",
       "3                 NaN          NaN          NaN        0        0        0  \n",
       "4                 NaN          NaN          NaN        0        0        0  \n",
       "...               ...          ...          ...      ...      ...      ...  \n",
       "59181085          NaN          NaN          NaN        0        0        0  \n",
       "59181086          NaN          NaN          NaN        0        0        0  \n",
       "59181087          NaN          NaN          NaN        0        0        0  \n",
       "59181088          NaN          NaN          NaN        0        0        0  \n",
       "59181089          NaN          NaN          NaN        0        0        0  \n",
       "\n",
       "[59181090 rows x 20 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing types\n",
    "icols = ['event_name_1',\n",
    "         'event_type_1',\n",
    "         'event_name_2',\n",
    "         'event_type_2',\n",
    "         'snap_CA',\n",
    "         'snap_TX',\n",
    "         'snap_WI']\n",
    "for col in icols:\n",
    "    grid_df[col] = grid_df[col].astype('category')\n",
    "\n",
    "# Convert to DateTime\n",
    "grid_df['date'] = pd.to_datetime(grid_df['date'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolling period: 7\n",
      "Rolling period: 14\n",
      "Rolling period: 30\n",
      "Rolling period: 60\n",
      "Rolling period: 180\n"
     ]
    }
   ],
   "source": [
    "SHIFT_DAY=28\n",
    "for i in [7,14,30,60,180]:\n",
    "    print('Rolling period:', i)\n",
    "    grid_df['rolling_mean_'+str(i)] = grid_df.groupby(['item_id'])[TARGET].transform(lambda x: x.shift(SHIFT_DAY).rolling(i).mean())\n",
    "    grid_df['rolling_std_'+str(i)]  = grid_df.groupby(['item_id'])[TARGET].transform(lambda x: x.shift(SHIFT_DAY).rolling(i).std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding ['state_id']\n",
      "Encoding ['store_id']\n",
      "Encoding ['cat_id']\n",
      "Encoding ['dept_id']\n",
      "Encoding ['state_id', 'cat_id']\n",
      "Encoding ['state_id', 'dept_id']\n",
      "Encoding ['store_id', 'cat_id']\n",
      "Encoding ['store_id', 'dept_id']\n",
      "Encoding ['item_id']\n",
      "Encoding ['item_id', 'state_id']\n",
      "Encoding ['item_id', 'store_id']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "icols =  [\n",
    "            ['state_id'],\n",
    "            ['store_id'],\n",
    "            ['cat_id'],\n",
    "            ['dept_id'],\n",
    "            ['state_id', 'cat_id'],\n",
    "            ['state_id', 'dept_id'],\n",
    "            ['store_id', 'cat_id'],\n",
    "            ['store_id', 'dept_id'],\n",
    "            ['item_id'],\n",
    "            ['item_id', 'state_id'],\n",
    "            ['item_id', 'store_id']\n",
    "            ]\n",
    "\n",
    "for col in icols:\n",
    "    print('Encoding', col)\n",
    "    col_name = '_'+'_'.join(col)+'_'\n",
    "    grid_df['enc'+col_name+'mean'] = grid_df.groupby(col)['sales'].transform('mean').astype(np.float16)\n",
    "    grid_df['enc'+col_name+'std'] = grid_df.groupby(col)['sales'].transform('std').astype(np.float16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    seed_everything(SEED)\n",
    "    estimator = lgb.train(lgb_params,\n",
    "                          train_data,\n",
    "                          valid_sets = [valid_data],\n",
    "                          verbose_eval = 100,\n",
    "                          )\n",
    "    \n",
    "    display(pd.DataFrame({'name':estimator.feature_name(),\n",
    "                          'imp':estimator.feature_importance()}).sort_values('imp',ascending=False).head(25))\n",
    "\n",
    "    \n",
    "    model_name = model_dir+'lgb_model_'+store_id+'_v'+str(VER)+'.bin'\n",
    "    pickle.dump(estimator, open(model_name, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved : /Users/sachadrevet/data_tmp/analysis/events.csv\n"
     ]
    }
   ],
   "source": [
    "from crptmidfreq.utils.common import to_csv\n",
    "to_csv(calendar_df.dropna(subset=['event_name_1']),'events')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
